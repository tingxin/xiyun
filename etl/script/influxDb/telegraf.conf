 # Global tags can be specified here in key="value" format.
 [global_tags]
   # dc = "us-east-1" # will tag all metrics with dc=us-east-1
   # rack = "1a"
   ## Environment variables can be used as tags, and throughout the config file
   # user = "$USER"


 # Configuration for telegraf agent
 [agent]
   ## Default data collection interval for all inputs
   interval = "10s"
   ## Rounds collection interval to 'interval'
   ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
   round_interval = true

   ## Telegraf will send metrics to outputs in batches of at most
   ## metric_batch_size metrics.
   ## This controls the size of writes that Telegraf sends to output plugins.
   metric_batch_size = 1000

   ## Maximum number of unwritten metrics per output.  Increasing this value
   ## allows for longer periods of output downtime without dropping metrics at the
   ## cost of higher maximum memory usage.
   metric_buffer_limit = 10000

   ## Collection jitter is used to jitter the collection by a random amount.
   ## Each plugin will sleep for a random time within jitter before collecting.
   ## This can be used to avoid many plugins querying things like sysfs at the
   ## same time, which can have a measurable effect on the system.
   collection_jitter = "0s"

   ## Default flushing interval for all outputs. Maximum flush_interval will be
   ## flush_interval + flush_jitter
   flush_interval = "10s"
   ## Jitter the flush interval by a random amount. This is primarily to avoid
   ## large write spikes for users running a large number of telegraf instances.
   ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
   flush_jitter = "0s"

   ## By default or when set to "0s", precision will be set to the same
   ## timestamp order as the collection interval, with the maximum being 1s.
   ##   ie, when interval = "10s", precision will be "1s"
   ##       when interval = "250ms", precision will be "1ms"
   ## Precision will NOT be used for service inputs. It is up to each individual
   ## service input to set the timestamp at the appropriate precision.
   ## Valid time units are "ns", "us" (or "Âµs"), "ms", "s".
   precision = ""

   ## Log at debug level.
   # debug = false
   ## Log only error level messages.
   # quiet = false

   ## Log target controls the destination for logs and can be one of "file",
   ## "stderr" or, on Windows, "eventlog".  When set to "file", the output file
   ## is determined by the "logfile" setting.
   # logtarget = "file"

   ## Name of the file to be logged to when using the "file" logtarget.  If set to
   ## the empty string then logs are written to stderr.
   # logfile = ""

   ## The logfile will be rotated after the time interval specified.  When set
   ## to 0 no time based rotation is performed.  Logs are rotated only when
   ## written to, if there is no log activity rotation may be delayed.
   # logfile_rotation_interval = "0d"

   ## The logfile will be rotated when it becomes larger than the specified
   ## size.  When set to 0 no size based rotation is performed.
   # logfile_rotation_max_size = "0MB"

   ## Maximum number of rotated archives to keep, any older logs are deleted.
   ## If set to -1, no archives are removed.
   # logfile_rotation_max_archives = 5

   ## Override default hostname, if empty use os.Hostname()
   hostname = ""
   ## If set to true, do no set the "host" tag in the telegraf agent.
   omit_hostname = false

 [[outputs.influxdb_v2]]
  ## The URLs of the InfluxDB cluster nodes.
  ##
  ## Multiple URLs can be specified for a single cluster, only ONE of the
  ## urls will be written to each interval.
  ## urls exp: http://127.0.0.1:9999
  urls = ["http://10.112.20.45:8086"]

  ## Token for authentication.
  token = "b5LxLOSNkpfzUD9Y1X4cbPi4Xa-eWGBSypd9yBiLKa-4dzVFHo9aWz2CTK1zfWpEMdKcBLwGNtLDHLYGNBQ9sg=="

  ## Organization is the name of the organization you wish to write to; must exist.
  organization = "org.verify.test"

  ## Destination bucket to write into.
  bucket = "event"

 [[inputs.kafka_consumer]]
   ## Kafka brokers.
   brokers = ["10.112.20.45:9092"]

   ## Topics to consume.test_data_event_sample_code
   topics = ["test"]

   ## When set this tag will be added to all metrics with the topic as the value.
   # topic_tag = ""
   topic_tag = "test_tag"

   ## Optional Client id
   client_id = "Telegraf"

   ## Set the minimal supported Kafka version.  Setting this enables the use of new
   ## Kafka features and APIs.  Must be 0.10.2.0 or greater.
   ##   ex: version = "1.1.0"
   # version = ""

   ## Optional TLS Config
   # tls_ca = "/etc/telegraf/ca.pem"
   # tls_cert = "/etc/telegraf/cert.pem"
   # tls_key = "/etc/telegraf/key.pem"
   ## Use TLS but skip chain & host verification
   # insecure_skip_verify = false

   ## SASL authentication credentials.  These settings should typically be used
   ## with TLS encryption enabled
   ## sasl_username = "admin"
   ## sasl_password = "abc"

   ## Optional SASL:
   ## one of: OAUTHBEARER, PLAIN, SCRAM-SHA-256, SCRAM-SHA-512, GSSAPI
   ## (defaults to PLAIN)
   # sasl_mechanism = "PLAIN"

   ## used if sasl_mechanism is GSSAPI (experimental)
   # sasl_gssapi_service_name = ""
   # ## One of: KRB5_USER_AUTH and KRB5_KEYTAB_AUTH
   # sasl_gssapi_auth_type = "KRB5_USER_AUTH"
   # sasl_gssapi_kerberos_config_path = "/"
   # sasl_gssapi_realm = "realm"
   # sasl_gssapi_key_tab_path = ""
   # sasl_gssapi_disable_pafxfast = false

   ## used if sasl_mechanism is OAUTHBEARER (experimental)
   # sasl_access_token = ""

   ## SASL protocol version.  When connecting to Azure EventHub set to 0.
   # sasl_version = 1

   ## Name of the consumer group.
   consumer_group = "telegraf_metrics_consumers"

   ## Compression codec represents the various compression codecs recognized by
   ## Kafka in messages.
   ##  0 : None
   ##  1 : Gzip
   ##  2 : Snappy
   ##  3 : LZ4
   ##  4 : ZSTD
   # compression_codec = 0
   ## Initial offset position; one of "oldest" or "newest".
   offset = "newest"

   ## Consumer group partition assignment strategy; one of "range", "roundrobin" or "sticky".
   # balance_strategy = "range"

   ## Maximum length of a message to consume, in bytes (default 0/unlimited);
   ## larger messages are dropped
   max_message_len = 1000000

   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md
   json_name_key = "name"
   name_override = "taxi"
   data_format = "json"
   json_time_format = "2006-01-02 15:04:05"
   json_time_key = "time"